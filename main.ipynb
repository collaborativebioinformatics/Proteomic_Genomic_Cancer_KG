{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58dcd48-4d23-4071-a17c-822e9dca30d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:26:46.724911Z",
     "iopub.status.busy": "2025-10-02T14:26:46.724433Z",
     "iopub.status.idle": "2025-10-02T14:26:49.482142Z",
     "shell.execute_reply": "2025-10-02T14:26:49.480975Z",
     "shell.execute_reply.started": "2025-10-02T14:26:46.724878Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas pyarrow torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb54680e-c859-4ddf-bc7c-a042e1adfe08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:26:51.148343Z",
     "iopub.status.busy": "2025-10-02T14:26:51.148045Z",
     "iopub.status.idle": "2025-10-02T14:26:51.152421Z",
     "shell.execute_reply": "2025-10-02T14:26:51.151715Z",
     "shell.execute_reply.started": "2025-10-02T14:26:51.148320Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765f7e3e-de0e-481d-86a3-860265f6532c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:27:03.542157Z",
     "iopub.status.busy": "2025-10-02T14:27:03.541854Z",
     "iopub.status.idle": "2025-10-02T14:27:03.548098Z",
     "shell.execute_reply": "2025-10-02T14:27:03.546655Z",
     "shell.execute_reply.started": "2025-10-02T14:27:03.542132Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPTAC COAD URLs (from your earlier messages)\n",
    "URLS = {\n",
    "    \"tumor_cases\": \"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_Tumor_CaseList.txt\",\n",
    "    \"normal_cases\": \"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_Normal_CaseList.txt\",\n",
    "    \"proteomics_tumor\": \"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_proteomics_gene_abundance_log2_reference_intensity_normalized_Tumor.txt\",\n",
    "    \"proteomics_normal\": \"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_proteomics_gene_abundance_log2_reference_intensity_normalized_Normal.txt\",\n",
    "    \"maf_gene_binary\": \"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_somatic_mutation_gene_level_binary.txt\",\n",
    "    # clinical .tsi with CMS / proteomic subtypes\n",
    "    \"linkedomics_tsi\": \"https://linkedomics.org/cptac-colon/Human__CPTAC_COAD__MS__Clinical__Clinical__03_01_2017__CPTAC__Clinical__BCM.tsi\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feeea0e1-df5e-483d-b148-22c27a0b1c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:28:30.008275Z",
     "iopub.status.busy": "2025-10-02T14:28:30.007326Z",
     "iopub.status.idle": "2025-10-02T14:28:30.015421Z",
     "shell.execute_reply": "2025-10-02T14:28:30.014321Z",
     "shell.execute_reply.started": "2025-10-02T14:28:30.008235Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_tsv(url, index_col=None):\n",
    "    r = requests.get(url); r.raise_for_status()\n",
    "    return pd.read_csv(StringIO(r.text), sep=\"\\t\", header=0, index_col=index_col)\n",
    "\n",
    "def strip_version(x):\n",
    "    # ENSG00000000003.15 -> ENSG00000000003\n",
    "    if isinstance(x, str) and x.startswith(\"ENSG\") and \".\" in x:\n",
    "        return x.split(\".\", 1)[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca465f83-3e29-47be-a1c6-bbf834d879de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:28:56.231622Z",
     "iopub.status.busy": "2025-10-02T14:28:56.231315Z",
     "iopub.status.idle": "2025-10-02T14:28:59.026157Z",
     "shell.execute_reply": "2025-10-02T14:28:59.025017Z",
     "shell.execute_reply.started": "2025-10-02T14:28:56.231599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9151, 97) (9151, 100) 9151\n"
     ]
    }
   ],
   "source": [
    "prot_tumor = fetch_tsv(URLS[\"proteomics_tumor\"], index_col=0)\n",
    "prot_norm  = fetch_tsv(URLS[\"proteomics_normal\"], index_col=0)\n",
    "\n",
    "prot_tumor.index = prot_tumor.index.map(strip_version)\n",
    "prot_norm.index  = prot_norm.index.map(strip_version)\n",
    "\n",
    "# Keep intersection of proteins for consistent processing\n",
    "common_prots = prot_tumor.index.intersection(prot_norm.index)\n",
    "prot_tumor = prot_tumor.loc[common_prots].copy()\n",
    "prot_norm  = prot_norm.loc[common_prots].copy()\n",
    "\n",
    "tumor_ids  = prot_tumor.columns.tolist()\n",
    "normal_ids = prot_norm.columns.tolist()\n",
    "\n",
    "print(prot_tumor.shape, prot_norm.shape, len(common_prots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4eebfd-6466-4d51-9860-147f24c17128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:32:58.051789Z",
     "iopub.status.busy": "2025-10-02T14:32:58.051506Z",
     "iopub.status.idle": "2025-10-02T14:32:58.408508Z",
     "shell.execute_reply": "2025-10-02T14:32:58.407745Z",
     "shell.execute_reply.started": "2025-10-02T14:32:58.051767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept patients with CMS labels: 85\n",
      "CMS classes -> {'CMS1': 0, 'CMS2': 1, 'CMS3': 2, 'CMS4': 3}\n"
     ]
    }
   ],
   "source": [
    "# --- 4) Load clinical .tsi and build CMS-only labels (drop NA / NaN) ---\n",
    "tsi = fetch_tsv(URLS[\"linkedomics_tsi\"])\n",
    "assert 'attrib_name' in tsi.columns, \"Unexpected .tsi format\"\n",
    "tsi = tsi.set_index('attrib_name')\n",
    "\n",
    "# Extract CMS row\n",
    "cms_labels = tsi.loc['Transcriptomic_subtype'].to_dict()\n",
    "\n",
    "# Keep only tumor patients that have valid CMS subtype (string, not NA)\n",
    "valid_pairs = [(pid, lab) for pid, lab in cms_labels.items() if isinstance(lab, str) and lab != \"NA\"]\n",
    "\n",
    "# Separate patient IDs and label strings\n",
    "kept_patients, labels_str = zip(*valid_pairs)\n",
    "kept_patients = list(kept_patients)\n",
    "labels_str = list(labels_str)\n",
    "\n",
    "# Build vocabulary\n",
    "classes = sorted(set(labels_str))   # e.g. ['CMS1','CMS2','CMS3','CMS4']\n",
    "vocab = {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "# Tensor of integer labels\n",
    "labels_y = torch.tensor([vocab[lab] for lab in labels_str], dtype=torch.long)\n",
    "\n",
    "print(f\"Kept patients with CMS labels: {len(kept_patients)}\")\n",
    "print(\"CMS classes ->\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed579c1-c910-463a-ad43-f8bda08a9912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:41:27.101152Z",
     "iopub.status.busy": "2025-10-02T14:41:27.100858Z",
     "iopub.status.idle": "2025-10-02T14:41:27.187564Z",
     "shell.execute_reply": "2025-10-02T14:41:27.186605Z",
     "shell.execute_reply.started": "2025-10-02T14:41:27.101129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After alignment: 76 tumor patients with CMS labels present in proteomics.\n",
      "Shapes -> X_prot: torch.Size([7, 6572]) | X_mask: torch.Size([7, 6572])\n",
      "#proteins: 6572 | #patients: 7\n"
     ]
    }
   ],
   "source": [
    "# --- 5) Clean + baseline-normalize tumors against normals (and define patient_ids/protein_ids) ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 5.0) Ensure inputs from previous cells exist:\n",
    "assert 'prot_tumor' in globals() and 'prot_norm' in globals(), \"Load proteomics first (Cell 3).\"\n",
    "assert 'kept_patients' in globals() and 'labels_y' in globals(), \"Build CMS labels first (Cell 4).\"\n",
    "\n",
    "# 5.1) Align CMS-labeled patients to proteomics tumor columns (avoid KeyError)\n",
    "prot_tumor.columns = [c.strip() for c in prot_tumor.columns]\n",
    "prot_norm.columns  = [c.strip() for c in prot_norm.columns]\n",
    "kp_clean = [p.strip() for p in kept_patients]\n",
    "\n",
    "pid_to_lab = {pid: lab for pid, lab in zip(kp_clean, labels_y.tolist())}\n",
    "kept_patients = [pid for pid in kp_clean if pid in prot_tumor.columns]\n",
    "labels_y      = torch.tensor([pid_to_lab[pid] for pid in kept_patients], dtype=torch.long)\n",
    "\n",
    "print(f\"After alignment: {len(kept_patients)} tumor patients with CMS labels present in proteomics.\")\n",
    "\n",
    "# 5.2) Subset tumor to labeled patients; keep all normals\n",
    "df_tumor = prot_tumor.loc[:, kept_patients].copy()\n",
    "df_norm_ = prot_norm.copy()\n",
    "\n",
    "# 5.3) Work on common proteins only\n",
    "common_prots = df_tumor.index.intersection(df_norm_.index)\n",
    "df_tumor = df_tumor.loc[common_prots].copy()\n",
    "df_norm_ = df_norm_.loc[common_prots].copy()\n",
    "\n",
    "# 5.4) Concatenate for consistent filtering across tumor+normal\n",
    "df_all = pd.concat([df_tumor, df_norm_], axis=1)\n",
    "\n",
    "# Missingness-based filtering (adjust thresholds as needed)\n",
    "PROT_MISS_MAX = 0.40   # drop proteins with >40% missing across ALL samples\n",
    "SAMP_MISS_MAX = 0.20   # drop samples with >20% missing proteins\n",
    "\n",
    "prot_miss = df_all.isna().mean(axis=1)\n",
    "samp_miss = df_all.isna().mean(axis=0)\n",
    "\n",
    "keep_prot = prot_miss <= PROT_MISS_MAX\n",
    "keep_samp = samp_miss <= SAMP_MISS_MAX\n",
    "df_all = df_all.loc[keep_prot, keep_samp]\n",
    "\n",
    "# Re-split after filtering\n",
    "tumor_ids_clean  = [c for c in df_all.columns if c in set(kept_patients)]\n",
    "normal_ids_clean = [c for c in df_all.columns if c in set(prot_norm.columns)]\n",
    "df_tumor = df_all.loc[:, tumor_ids_clean]\n",
    "df_norm  = df_all.loc[:, normal_ids_clean]\n",
    "\n",
    "# 5.5) Missingness mask BEFORE imputation (for tumor only)\n",
    "miss_mask_tumor = df_tumor.isna().astype(np.float32)\n",
    "\n",
    "# 5.6) Impute remaining NAs with per-protein median (robust after filtering)\n",
    "row_median_all = df_all.median(axis=1, skipna=True)\n",
    "df_tumor_imp = df_tumor.apply(lambda col: col.fillna(row_median_all), axis=0)\n",
    "df_norm_imp  = df_norm.apply(lambda col: col.fillna(row_median_all), axis=0)\n",
    "\n",
    "# 5.7) Baseline stats from NORMALS ONLY (no leakage)\n",
    "mean_norm = df_norm_imp.mean(axis=1)\n",
    "std_norm  = df_norm_imp.std(axis=1, ddof=0).replace(0, np.nan)\n",
    "\n",
    "# 5.8) Baseline-normalized tumor z (clip extremes)\n",
    "Z_CLIP = 5.0\n",
    "z_baseline = (df_tumor_imp.sub(mean_norm, axis=0)).div(std_norm, axis=0).fillna(0.0).clip(-Z_CLIP, Z_CLIP)\n",
    "\n",
    "# 5.9) Define IDs and build tensors\n",
    "protein_ids = z_baseline.index.tolist()         # <--- proteins after filtering\n",
    "patient_ids = z_baseline.columns.tolist()       # <--- tumors after filtering\n",
    "\n",
    "X_prot = torch.tensor(z_baseline.T.values, dtype=torch.float32)  # [P, N]\n",
    "X_mask = torch.tensor(miss_mask_tumor.loc[protein_ids, patient_ids].T.values,\n",
    "                      dtype=torch.float32)                        # [P, N]\n",
    "\n",
    "print(\"Shapes -> X_prot:\", X_prot.shape, \"| X_mask:\", X_mask.shape)\n",
    "print(\"#proteins:\", len(protein_ids), \"| #patients:\", len(patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3238a7dc-ec60-4a8c-aa66-912fdf28c64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:46:05.898329Z",
     "iopub.status.busy": "2025-10-02T14:46:05.898036Z",
     "iopub.status.idle": "2025-10-02T14:46:06.010846Z",
     "shell.execute_reply": "2025-10-02T14:46:06.009262Z",
     "shell.execute_reply.started": "2025-10-02T14:46:05.898306Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 samples from classes with <2 members: [0, 3]\n",
      "Class counts after filtering: [3 2]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=2 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m     n_splits_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     61\u001b[0m skf2 \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mn_splits_val, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m43\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m rest_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mskf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_rest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_rest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m train_sub, val_sub \u001b[38;5;241m=\u001b[39m rest_folds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], rest_folds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     64\u001b[0m train_idx \u001b[38;5;241m=\u001b[39m rest_idx[train_sub]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:411\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    405\u001b[0m         (\n\u001b[1;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    409\u001b[0m     )\n\u001b[0;32m--> 411\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:142\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    140\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    141\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 142\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_test_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:844\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 844\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[1;32m    846\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:806\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    804\u001b[0m min_groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(y_counts)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m y_counts):\n\u001b[0;32m--> 806\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m cannot be greater than the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of members in each class.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits)\n\u001b[1;32m    809\u001b[0m     )\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m min_groups:\n\u001b[1;32m    811\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m members, which is less than n_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;241m%\u001b[39m (min_groups, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits),\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    816\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=2 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 6.1) Align labels to patient_ids (from Cell 5)\n",
    "if 'patient_ids' not in globals():\n",
    "    raise RuntimeError(\"patient_ids not defined — re-run Cell 5 first.\")\n",
    "\n",
    "pid_to_lab = {pid: lab for pid, lab in zip(kept_patients, labels_y.tolist())}\n",
    "labels_aligned = torch.tensor([pid_to_lab[pid] for pid in patient_ids if pid in pid_to_lab],\n",
    "                              dtype=torch.long)\n",
    "\n",
    "# ensure X_prot/X_mask are in the same order as patient_ids already (Cell 5 did that)\n",
    "assert X_prot.shape[0] == len(patient_ids), \"X_prot rows must match patient_ids length.\"\n",
    "assert X_mask.shape[0] == len(patient_ids), \"X_mask rows must match patient_ids length.\"\n",
    "\n",
    "# 6.2) Drop classes with <2 samples (Stratified splitting requires >=2 per class)\n",
    "y_np = labels_aligned.numpy()\n",
    "counts = np.bincount(y_np, minlength=int(y_np.max()+1))\n",
    "rare_classes = np.where(counts < 2)[0].tolist()\n",
    "\n",
    "if len(rare_classes) > 0:\n",
    "    mask = ~np.isin(y_np, rare_classes)\n",
    "    kept_before = len(y_np)\n",
    "    # filter all aligned arrays\n",
    "    patient_ids = [p for p, m in zip(patient_ids, mask) if m]\n",
    "    X_prot      = X_prot[mask]\n",
    "    X_mask      = X_mask[mask]\n",
    "    labels_aligned = labels_aligned[mask]\n",
    "    y_np = labels_aligned.numpy()\n",
    "    print(f\"Dropped {kept_before - len(y_np)} samples from classes with <2 members:\", rare_classes)\n",
    "\n",
    "# 6.3) Remap labels to 0..C'-1 after dropping\n",
    "unique = sorted(np.unique(y_np))\n",
    "remap = {old:i for i, old in enumerate(unique)}\n",
    "labels_aligned = torch.tensor([remap[int(v)] for v in y_np], dtype=torch.long)\n",
    "y_np = labels_aligned.numpy()\n",
    "n_classes = len(unique)\n",
    "print(\"Class counts after filtering:\", np.bincount(y_np))\n",
    "\n",
    "# 6.4) Use StratifiedKFold to create test and val folds robustly\n",
    "min_count = np.bincount(y_np).min()\n",
    "if min_count < 2:\n",
    "    raise RuntimeError(\"Still have a class with <2 samples after filtering.\")\n",
    "\n",
    "# choose number of folds based on the rarest class\n",
    "n_splits = min(5, int(min_count))  # at least 2\n",
    "if n_splits < 2:\n",
    "    n_splits = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "folds = list(skf.split(np.zeros_like(y_np), y_np))\n",
    "\n",
    "# Take the first fold's test indices; rest is train+val\n",
    "rest_idx, test_idx = folds[0][0], folds[0][1]\n",
    "\n",
    "# Now split rest into train/val using another StratifiedKFold\n",
    "y_rest = y_np[rest_idx]\n",
    "min_count_rest = np.bincount(y_rest).min()\n",
    "n_splits_val = min(5, int(min_count_rest))\n",
    "if n_splits_val < 2:\n",
    "    n_splits_val = 2\n",
    "skf2 = StratifiedKFold(n_splits=n_splits_val, shuffle=True, random_state=43)\n",
    "rest_folds = list(skf2.split(np.zeros_like(y_rest), y_rest))\n",
    "train_sub, val_sub = rest_folds[0][0], rest_folds[0][1]\n",
    "train_idx = rest_idx[train_sub]\n",
    "val_idx   = rest_idx[val_sub]\n",
    "\n",
    "print(f\"Split sizes -> train={len(train_idx)} val={len(val_idx)} test={len(test_idx)}\")\n",
    "\n",
    "# Build the patient ID lists (useful for logging/debug)\n",
    "train_patients = [patient_ids[i] for i in train_idx]\n",
    "val_patients   = [patient_ids[i] for i in val_idx]\n",
    "test_patients  = [patient_ids[i] for i in test_idx]\n",
    "\n",
    "# 6.5) Slice tensors and labels for each split\n",
    "def take_rows(X, idx): return X[idx]\n",
    "\n",
    "X_train, X_val, X_test = take_rows(X_prot, train_idx), take_rows(X_prot, val_idx), take_rows(X_prot, test_idx)\n",
    "M_train, M_val, M_test = take_rows(X_mask, train_idx), take_rows(X_mask, val_idx), take_rows(X_mask, test_idx)\n",
    "y_train, y_val, y_test = labels_aligned[train_idx], labels_aligned[val_idx], labels_aligned[test_idx]\n",
    "\n",
    "print(\"Shapes ->\",\n",
    "      \"X_train\", X_train.shape, \"X_val\", X_val.shape, \"X_test\", X_test.shape,\n",
    "      \"| y_train\", y_train.shape, \"y_val\", y_val.shape, \"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f95fd23-e358-4293-a91f-2a2fb850503e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T12:57:39.360050Z",
     "iopub.status.busy": "2025-10-02T12:57:39.359775Z",
     "iopub.status.idle": "2025-10-02T12:57:39.385608Z",
     "shell.execute_reply": "2025-10-02T12:57:39.384739Z",
     "shell.execute_reply.started": "2025-10-02T12:57:39.360027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: COAD_X_proteomics_tumor_z.pt, IDs, norm stats, and mutation edges (if available).\n"
     ]
    }
   ],
   "source": [
    "# Save key artifacts\n",
    "pd.Series(patient_ids_tumor).to_csv(\"COAD_patient_ids_tumor.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "pd.Series(protein_ids).to_csv(\"COAD_protein_ids.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "torch.save(X_prot_tumor_z, \"COAD_X_proteomics_tumor_z.pt\")\n",
    "if mut_edge_index is not None:\n",
    "    torch.save(mut_edge_index, \"COAD_mut_edge_index.pt\")\n",
    "\n",
    "print(\"Saved: COAD_X_proteomics_tumor_z.pt, IDs, norm stats, and mutation edges (if available).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71ed0e9a-8431-4b3b-a7fa-aed3c3e7cad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T12:57:42.244384Z",
     "iopub.status.busy": "2025-10-02T12:57:42.244069Z",
     "iopub.status.idle": "2025-10-02T12:57:42.260561Z",
     "shell.execute_reply": "2025-10-02T12:57:42.258830Z",
     "shell.execute_reply.started": "2025-10-02T12:57:42.244358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded proteomics: 97 patients × 9151 proteins\n"
     ]
    }
   ],
   "source": [
    "# ---- paths from your earlier saving step\n",
    "X_path = Path(\"COAD_X_proteomics_tumor_z.pt\")\n",
    "patients_path = Path(\"COAD_patient_ids_tumor.tsv\")\n",
    "proteins_path = Path(\"COAD_protein_ids.tsv\")\n",
    "\n",
    "assert X_path.exists() and patients_path.exists() and proteins_path.exists(), \"Run the earlier ingest cell first.\"\n",
    "\n",
    "# Proteomics (z-scored) — shape [n_patients, n_proteins]\n",
    "X_prot = torch.load(X_path)  # FloatTensor\n",
    "patient_ids = pd.read_csv(patients_path, sep=\"\\t\", header=None)[0].astype(str).tolist()\n",
    "protein_ids = pd.read_csv(proteins_path,  sep=\"\\t\", header=None)[0].astype(str).tolist()\n",
    "\n",
    "n_patients, n_proteins = X_prot.shape\n",
    "print(f\"Loaded proteomics: {n_patients} patients × {n_proteins} proteins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b9e65cb5-f556-4a06-96f0-84eac858fe69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:03:00.397789Z",
     "iopub.status.busy": "2025-10-02T13:03:00.397365Z",
     "iopub.status.idle": "2025-10-02T13:03:01.351788Z",
     "shell.execute_reply": "2025-10-02T13:03:01.344130Z",
     "shell.execute_reply.started": "2025-10-02T13:03:00.397760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation table aligned: (9151, 96)\n"
     ]
    }
   ],
   "source": [
    "# Align mutation table\n",
    "mut = pd.read_csv(URLS[\"maf_gene_binary\"], sep=\"\\t\", header=0, index_col=0)\n",
    "\n",
    "# Normalize identifiers to match our protein_ids (strip Ensembl version if present)\n",
    "def strip_version(x):\n",
    "    if isinstance(x, str) and x.startswith(\"ENSG\") and \".\" in x:\n",
    "        return x.split(\".\")[0]\n",
    "    return x\n",
    "\n",
    "mut.index = mut.index.map(strip_version)\n",
    "\n",
    "# Keep only our cohort & protein list\n",
    "mut = mut.reindex(index=protein_ids)               # rows aligned to our proteins\n",
    "mut = mut[[c for c in mut.columns if c in set(patient_ids)]]  # cols aligned to our patients\n",
    "mut = mut.fillna(0).astype(int)\n",
    "\n",
    "# Build per-patient mutated protein index lists\n",
    "patient_idx_map = {pid:i for i, pid in enumerate(patient_ids)}\n",
    "mutated_indices_by_patient = [\n",
    "    np.where(mut.iloc[:, j].values == 1)[0].astype(np.int64)\n",
    "    for j in range(mut.shape[1])\n",
    "]\n",
    "#print(mutated_indices_by_patient)\n",
    "print(\"Mutation table aligned:\", mut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a689fe1c-b745-4c7b-9c10-45082c78b808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T12:57:56.300481Z",
     "iopub.status.busy": "2025-10-02T12:57:56.300198Z",
     "iopub.status.idle": "2025-10-02T12:57:56.643599Z",
     "shell.execute_reply": "2025-10-02T12:57:56.642615Z",
     "shell.execute_reply.started": "2025-10-02T12:57:56.300458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "tsi_url = \n",
    "tsi = pd.read_csv(tsi_url, sep=\"\\t\")  # wide 'attrib_name' table\n",
    "assert 'attrib_name' in tsi.columns, \"Unexpected .tsi format\"\n",
    "tsi = tsi.set_index('attrib_name')\n",
    "\n",
    "# two rows we care about\n",
    "cms_row  = tsi.loc['Transcriptomic_subtype']      # values: CMS1..CMS4 or 'NA'\n",
    "prot_row = tsi.loc['Proteomic_subtype']           # values: A..E or 'NA'\n",
    "\n",
    "# turn into dicts: {sample_id -> label_str}\n",
    "cms_labels  = cms_row.to_dict()\n",
    "prot_labels = prot_row.to_dict()\n",
    "print(len(cms_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6ee22aa-3a27-48f2-aacd-80b9df7d72b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:21:59.933464Z",
     "iopub.status.busy": "2025-10-02T13:21:59.933069Z",
     "iopub.status.idle": "2025-10-02T13:21:59.938185Z",
     "shell.execute_reply": "2025-10-02T13:21:59.937188Z",
     "shell.execute_reply.started": "2025-10-02T13:21:59.933429Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preferred: CMS (Transcriptomic_subtype). If missing for a sample, we can fall back to proteomic subtype.\n",
    "use_fallback_to_proteomic = False\n",
    "\n",
    "label_strs = []\n",
    "for pid in patient_ids:\n",
    "    lab = cms_labels.get(pid, 'NA')\n",
    "    if lab == 'NA' and use_fallback_to_proteomic:\n",
    "        lab = prot_labels.get(pid, 'NA')\n",
    "    label_strs.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31a1cb9b-4d7b-4eec-8e2f-6bd5d5c81281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:22:06.573760Z",
     "iopub.status.busy": "2025-10-02T13:22:06.573470Z",
     "iopub.status.idle": "2025-10-02T13:22:06.579964Z",
     "shell.execute_reply": "2025-10-02T13:22:06.578817Z",
     "shell.execute_reply.started": "2025-10-02T13:22:06.573735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled patients kept: 76 / 97\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Filter to labeled patients & build integer labels ---\n",
    "keep_mask = np.array([lab != 'NA' and isinstance(lab, str) for lab in label_strs], dtype=bool)\n",
    "kept_patients = [p for p, k in zip(patient_ids, keep_mask) if k]\n",
    "print(f\"Labeled patients kept: {keep_mask.sum()} / {len(patient_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "786bf00f-cd41-461c-b80c-0c4411ae8d28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:22:08.387093Z",
     "iopub.status.busy": "2025-10-02T13:22:08.386677Z",
     "iopub.status.idle": "2025-10-02T13:22:08.391628Z",
     "shell.execute_reply": "2025-10-02T13:22:08.390755Z",
     "shell.execute_reply.started": "2025-10-02T13:22:08.387063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label vocabulary: {'CMS1': 0, 'CMS2': 1, 'CMS3': 2, 'CMS4': 3}\n"
     ]
    }
   ],
   "source": [
    "# choose vocabulary over actually present labels\n",
    "present_labels = sorted({lab for lab, k in zip(label_strs, keep_mask) if k})\n",
    "label_vocab = {lab:i for i, lab in enumerate(present_labels)}\n",
    "print(\"Label vocabulary:\", label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b8a132d-5e3d-47a9-aeb0-d979735e5b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:22:11.763256Z",
     "iopub.status.busy": "2025-10-02T13:22:11.762957Z",
     "iopub.status.idle": "2025-10-02T13:22:11.768257Z",
     "shell.execute_reply": "2025-10-02T13:22:11.767399Z",
     "shell.execute_reply.started": "2025-10-02T13:22:11.763221Z"
    }
   },
   "outputs": [],
   "source": [
    "# indices of kept patients\n",
    "kept_idx = np.where(keep_mask)[0]\n",
    "# tensors aligned to kept patients\n",
    "X_prot_kept = X_prot[kept_idx]  # [P_kept, N]\n",
    "labels_y    = torch.tensor([label_vocab[label_strs[i]] for i in kept_idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1485af77-c311-446b-939c-5e885adf4371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:22:17.675514Z",
     "iopub.status.busy": "2025-10-02T13:22:17.675235Z",
     "iopub.status.idle": "2025-10-02T13:22:17.698590Z",
     "shell.execute_reply": "2025-10-02T13:22:17.697815Z",
     "shell.execute_reply.started": "2025-10-02T13:22:17.675491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity: 76 lists; first 5 sizes -> [63, 477, 40, 799, 31]\n"
     ]
    }
   ],
   "source": [
    "def strip_version(x):\n",
    "    if isinstance(x, str) and x.startswith(\"ENSG\") and \".\" in x:\n",
    "        return x.split(\".\", 1)[0]\n",
    "    return x\n",
    "\n",
    "# 1) make row IDs (genes/proteins) comparable and align them to your protein node order\n",
    "mut.index = mut.index.map(strip_version)\n",
    "mut = mut.reindex(index=protein_ids)  # rows now in same order as your protein nodes\n",
    "\n",
    "# 2) build patient->indices dict, only for the kept patients (labels available)\n",
    "pid_to_mutidx = {}\n",
    "for pid in kept_patients:\n",
    "    if pid in mut.columns:\n",
    "        col = mut[pid].fillna(0).astype(int).values  # length = len(protein_ids)\n",
    "        pid_to_mutidx[pid] = np.where(col == 1)[0].astype(np.int64)\n",
    "    else:\n",
    "        pid_to_mutidx[pid] = np.array([], dtype=np.int64)\n",
    "\n",
    "# 3) assemble the final list in exact kept order (matches X_prot_kept / labels_y)\n",
    "mut_idx_by_patient_kept = [pid_to_mutidx[pid] for pid in kept_patients]\n",
    "\n",
    "print(\"Sanity:\", len(mut_idx_by_patient_kept), \"lists; first 5 sizes ->\",\n",
    "      [len(a) for a in mut_idx_by_patient_kept[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f942cea4-455a-4e53-9270-374087ceed13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:08:43.460408Z",
     "iopub.status.busy": "2025-10-02T14:08:43.460127Z",
     "iopub.status.idle": "2025-10-02T14:08:43.468475Z",
     "shell.execute_reply": "2025-10-02T14:08:43.467799Z",
     "shell.execute_reply.started": "2025-10-02T14:08:43.460385Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv, global_mean_pool\n",
    "\n",
    "class KGNNWithProteinReadout(nn.Module):\n",
    "    def __init__(self, in_protein=1, in_patient=1, hidden=128, n_classes=4):\n",
    "        super().__init__()\n",
    "        self.lin_prot_in  = nn.Linear(in_protein, hidden)\n",
    "        self.lin_pat_in   = nn.Linear(in_patient, hidden)\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('patient','mutated','protein'):     SAGEConv((-1, -1), hidden),\n",
    "            ('protein','rev_mutated','patient'): SAGEConv((-1, -1), hidden),\n",
    "        }, aggr='sum')\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('patient','mutated','protein'):     SAGEConv((-1, -1), hidden),\n",
    "            ('protein','rev_mutated','patient'): SAGEConv((-1, -1), hidden),\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.lin_fuse   = nn.Linear(2*hidden, hidden)\n",
    "        self.classifier = nn.Linear(hidden, n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        x = {\n",
    "            'protein': F.relu(self.lin_prot_in(g['protein'].x)),\n",
    "            'patient': F.relu(self.lin_pat_in(g['patient'].x)),\n",
    "        }\n",
    "        x = self.conv1(x, g.edge_index_dict); x = {k: F.relu(v) for k,v in x.items()}\n",
    "        x = self.conv2(x, g.edge_index_dict); x = {k: F.relu(v) for k,v in x.items()}\n",
    "\n",
    "        # --- pool PER GRAPH using batch vectors ---\n",
    "        prot_batch = g['protein'].batch if 'batch' in g['protein'] else torch.zeros(\n",
    "            x['protein'].size(0), dtype=torch.long, device=x['protein'].device\n",
    "        )\n",
    "        pat_batch  = g['patient'].batch if 'batch' in g['patient'] else torch.zeros(\n",
    "            x['patient'].size(0), dtype=torch.long, device=x['patient'].device\n",
    "        )\n",
    "\n",
    "        z_prot = global_mean_pool(x['protein'], prot_batch)   # [B, H]\n",
    "        z_pat  = global_mean_pool(x['patient'], pat_batch)    # [B, H] (safe even if 1 node/graph)\n",
    "\n",
    "        z = torch.cat([z_pat, z_prot], dim=-1)                # [B, 2H]\n",
    "        z = F.relu(self.lin_fuse(z))\n",
    "        logits = self.classifier(z)                           # [B, C]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd83231-b6dd-452c-9e6b-479f45723480",
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-02T14:09:35.559Z",
     "iopub.execute_input": "2025-10-02T14:08:55.390700Z",
     "iopub.status.busy": "2025-10-02T14:08:55.390190Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train 1.398/0.151 | val 1.388/0.273\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_classes = int(labels_y.max().item() + 1)\n",
    "\n",
    "model = KGNNWithProteinReadout(in_protein=1, in_patient=1, hidden=128, n_classes=n_classes).to(device)\n",
    "\n",
    "# optional: class-weighted loss for imbalance\n",
    "cnt = Counter(labels_y.numpy().tolist())\n",
    "weights = torch.tensor([1.0 / cnt[i] for i in range(n_classes)], dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for g in loader:\n",
    "        g = g.to(device)\n",
    "        logits = model(g)                # [B_graphs?, n_classes] (here 1 per g)\n",
    "        y = g['patient'].y.view(-1).to(device)\n",
    "        loss = criterion(logits, y)\n",
    "        if train:\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        total_loss += float(loss.item())\n",
    "        pred = logits.argmax(dim=-1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += y.size(0)\n",
    "    acc = correct / max(total, 1)\n",
    "    return total_loss / max(len(loader), 1), acc\n",
    "\n",
    "best_val, best_state = 0.0, None\n",
    "for epoch in range(1, 31):  # 30 epochs to start\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   False)\n",
    "    if va_acc > best_val:\n",
    "        best_val = va_acc\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "    print(f\"Epoch {epoch:02d} | train {tr_loss:.3f}/{tr_acc:.3f} | val {va_loss:.3f}/{va_acc:.3f}\")\n",
    "\n",
    "# Load best weights and evaluate on test\n",
    "model.load_state_dict(best_state)\n",
    "te_loss, te_acc = run_epoch(test_loader, False)\n",
    "print(f\"TEST acc: {te_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c9252-4ec5-4a7a-95ec-987d69d80986",
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-02T14:09:35.560Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 0  # pick an index in 0..len(dataset)-1 within the kept subset\n",
    "g = dataset[k].to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g)\n",
    "probs = logits.softmax(dim=-1).cpu().numpy()[0]\n",
    "pred_class = int(probs.argmax())\n",
    "print(\"Pred class:\", pred_class, \"probs:\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89f79339-297f-4206-94af-51b17b992adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T13:06:48.252501Z",
     "iopub.status.busy": "2025-10-02T13:06:48.252204Z",
     "iopub.status.idle": "2025-10-02T13:06:49.006674Z",
     "shell.execute_reply": "2025-10-02T13:06:49.005727Z",
     "shell.execute_reply.started": "2025-10-02T13:06:48.252477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits -> train=53 val=11 test=12\n"
     ]
    }
   ],
   "source": [
    "# --- 4) Update the Dataset to take externally provided labels & patient subset ---\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "class PatientGraphDatasetLabeled(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_prot, mutated_idx_by_patient, labels):\n",
    "        self.X = X_prot                              # [P, N]\n",
    "        self.mut_idx = mutated_idx_by_patient        # list of np arrays\n",
    "        self.labels = labels                         # torch.long [P]\n",
    "        self.n_patients, self.n_proteins = X_prot.shape\n",
    "\n",
    "        self.template = HeteroData()\n",
    "        self.template['protein'].x = torch.zeros(self.n_proteins, 1)   # abundance channel\n",
    "        self.template['patient'].x = torch.zeros(1, 1)                 # (optional covars slot)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_patients\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        g = self.template.clone()\n",
    "        g['protein'].x[:, 0] = self.X[i]\n",
    "\n",
    "        mut_idx = self.mut_idx[i]\n",
    "        if mut_idx.size > 0:\n",
    "            src = torch.zeros(len(mut_idx), dtype=torch.long)              # patient node index 0\n",
    "            dst = torch.tensor(mut_idx, dtype=torch.long)                  # protein indices\n",
    "            g[('patient','mutated','protein')].edge_index = torch.stack([src, dst], dim=0)\n",
    "            # add reverse edges so messages can flow back to patient\n",
    "            r_src = dst.clone()\n",
    "            r_dst = torch.zeros_like(src)\n",
    "            g[('protein','rev_mutated','patient')].edge_index = torch.stack([r_src, r_dst], dim=0)\n",
    "        else:\n",
    "            g[('patient','mutated','protein')].edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "            g[('protein','rev_mutated','patient')].edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "\n",
    "        # supervision on patient node\n",
    "        g['patient'].y = self.labels[i:i+1]\n",
    "        return g\n",
    "\n",
    "dataset = PatientGraphDatasetLabeled(X_prot_kept, mut_idx_by_patient_kept, labels_y)\n",
    "\n",
    "# --- 5) Stratified split (by label) ---\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "y_np = labels_y.numpy()\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, temp_idx = next(sss1.split(np.zeros_like(y_np), y_np))\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(sss2.split(np.zeros_like(y_np[temp_idx]), y_np[temp_idx]))\n",
    "val_idx  = temp_idx[val_idx]\n",
    "test_idx = temp_idx[test_idx]\n",
    "\n",
    "train_loader = DataLoader(torch.utils.data.Subset(dataset, train_idx.tolist()), batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(torch.utils.data.Subset(dataset, val_idx.tolist()),   batch_size=16)\n",
    "test_loader  = DataLoader(torch.utils.data.Subset(dataset, test_idx.tolist()),  batch_size=16)\n",
    "print(f\"Splits -> train={len(train_idx)} val={len(val_idx)} test={len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b45d3-cecf-4c1d-9967-947959ae0862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54095bf5-c813-4a6a-bb71-c5c51d7e1ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T02:09:33.565952Z",
     "iopub.status.busy": "2025-10-02T02:09:33.565680Z",
     "iopub.status.idle": "2025-10-02T02:09:34.011843Z",
     "shell.execute_reply": "2025-10-02T02:09:34.010911Z",
     "shell.execute_reply.started": "2025-10-02T02:09:33.565930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         idx  CIBERSORT_B_cell_naive  CIBERSORT_B_cell_memory  \\\n",
      "0    01CO001                0.170660                 0.025228   \n",
      "1    01CO005                0.105408                 0.000000   \n",
      "2    01CO006                0.400195                 0.485658   \n",
      "3    01CO008                0.008900                 0.023195   \n",
      "4    01CO013                0.122969                 0.000000   \n",
      "..       ...                     ...                      ...   \n",
      "105  21CO007                0.000000                 0.043618   \n",
      "106  22CO004                0.000000                 0.099148   \n",
      "107  22CO006                0.076124                 0.129644   \n",
      "108  24CO005                0.050307                 0.073352   \n",
      "109  27CO004                0.116184                 0.059798   \n",
      "\n",
      "     CIBERSORT_B_cell_plasma  CIBERSORT_T_cell_CD8+  \\\n",
      "0                   0.149748               0.154231   \n",
      "1                   0.047860               0.169397   \n",
      "2                   0.000000               0.867519   \n",
      "3                   0.125100               0.074297   \n",
      "4                   0.097589               0.214291   \n",
      "..                       ...                    ...   \n",
      "105                 0.090125               0.203102   \n",
      "106                 0.080269               0.201738   \n",
      "107                 0.014724               0.507140   \n",
      "108                 0.051005               0.348073   \n",
      "109                 0.000000               0.207488   \n",
      "\n",
      "     CIBERSORT_T_cell_CD4+_naive  CIBERSORT_T_cell_CD4+_memory_resting  \\\n",
      "0                            0.0                              1.203715   \n",
      "1                            0.0                              0.531334   \n",
      "2                            0.0                              0.661537   \n",
      "3                            0.0                              0.546903   \n",
      "4                            0.0                              1.010830   \n",
      "..                           ...                                   ...   \n",
      "105                          0.0                              0.448117   \n",
      "106                          0.0                              0.633965   \n",
      "107                          0.0                              1.139389   \n",
      "108                          0.0                              0.549395   \n",
      "109                          0.0                              0.691681   \n",
      "\n",
      "     CIBERSORT_T_cell_CD4+_memory_activated  \\\n",
      "0                                  0.008398   \n",
      "1                                  0.000000   \n",
      "2                                  0.000000   \n",
      "3                                  0.042627   \n",
      "4                                  0.406273   \n",
      "..                                      ...   \n",
      "105                                0.131077   \n",
      "106                                0.008246   \n",
      "107                                0.592720   \n",
      "108                                0.144096   \n",
      "109                                0.000000   \n",
      "\n",
      "     CIBERSORT_T_cell_follicular_helper  CIBERSORT_T_cell_regulatory_(Tregs)  \\\n",
      "0                              0.024703                             0.000000   \n",
      "1                              0.000000                             0.000000   \n",
      "2                              0.256846                             0.252728   \n",
      "3                              0.000000                             0.000000   \n",
      "4                              0.039253                             0.021197   \n",
      "..                                  ...                                  ...   \n",
      "105                            0.000000                             0.125270   \n",
      "106                            0.042969                             0.109880   \n",
      "107                            0.000000                             0.000000   \n",
      "108                            0.216826                             0.000000   \n",
      "109                            0.160495                             0.082950   \n",
      "\n",
      "     ...  Mutation_signature_SBS10a  Mutation_signature_SBS10b  \\\n",
      "0    ...                        NaN                        NaN   \n",
      "1    ...                        0.0                        0.0   \n",
      "2    ...                        0.0                        0.0   \n",
      "3    ...                        0.0                        0.0   \n",
      "4    ...                        0.0                        0.0   \n",
      "..   ...                        ...                        ...   \n",
      "105  ...                        0.0                        0.0   \n",
      "106  ...                        0.0                        0.0   \n",
      "107  ...                        0.0                        0.0   \n",
      "108  ...                        NaN                        NaN   \n",
      "109  ...                        0.0                        0.0   \n",
      "\n",
      "     Mutation_signature_SBS15  Mutation_signature_SBS20  \\\n",
      "0                         NaN                       NaN   \n",
      "1                         0.0                       0.0   \n",
      "2                         0.0                       0.0   \n",
      "3                         0.0                       0.0   \n",
      "4                         0.0                       0.0   \n",
      "..                        ...                       ...   \n",
      "105                       0.0                       0.0   \n",
      "106                       0.0                       0.0   \n",
      "107                     520.0                       0.0   \n",
      "108                       NaN                       NaN   \n",
      "109                       0.0                       0.0   \n",
      "\n",
      "     Mutation_signature_SBS26  Mutation_signature_SBS40  POLE  WES_purity  \\\n",
      "0                         NaN                       NaN    No        0.33   \n",
      "1                         0.0                     107.0    No        0.59   \n",
      "2                         0.0                       0.0    No        0.23   \n",
      "3                         0.0                       0.0    No        0.56   \n",
      "4                         0.0                      40.0    No        0.57   \n",
      "..                        ...                       ...   ...         ...   \n",
      "105                       0.0                      83.0    No        0.55   \n",
      "106                       0.0                      48.0    No        0.23   \n",
      "107                       0.0                       0.0    No        0.24   \n",
      "108                       NaN                       NaN    No        0.39   \n",
      "109                       0.0                       0.0    No        0.48   \n",
      "\n",
      "     WES_ploidy    TMB  \n",
      "0          2.08    NaN  \n",
      "1          4.21   2.70  \n",
      "2          2.03   0.26  \n",
      "3          3.45   2.92  \n",
      "4          2.04   1.34  \n",
      "..          ...    ...  \n",
      "105        2.64   3.04  \n",
      "106        5.13   1.54  \n",
      "107        1.98  19.70  \n",
      "108        3.04    NaN  \n",
      "109        1.87   2.10  \n",
      "\n",
      "[110 rows x 185 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---- load phenotype for labels (if available)\n",
    "pheno_url = \"https://cptac-pancancer-data.s3.us-west-2.amazonaws.com/data_freeze_v1.2_reorganized/COAD/COAD_phenotype.txt\"\n",
    "ph = pd.read_csv(pheno_url, sep=\"\\t\", header=0)\n",
    "print(ph)\n",
    "\n",
    "# Heuristic: find a plausible subtype column (adjust to your truth column)\n",
    "candidate_cols = [c for c in ph.columns if \"CMS\" in c.upper() or \"SUBTYPE\" in c.upper()]\n",
    "label_col = candidate_cols[0] if candidate_cols else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca0df2-7b55-4db2-a92d-1e29e872b0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
